{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Histopathologic Cancer Detection\n### William Egesdal","metadata":{}},{"cell_type":"markdown","source":"## Problem Description\n\nThe corpus is made up of labeled medical images. The problem is binary classification of cells to determine a positive or negative diagnosis. Two directories of images are provided (train and test), as well as a csv file of labels for the training set. The training and test sets are made up of 220025 and 57458 images respectively. The images are 96x96 pixels and are RGB which gives a flattened dimension of 27648. The files are in .tif format. The problem is well-suited to Convolutional Neural Network (CNN) Classification.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-01T05:43:53.836463Z","iopub.execute_input":"2021-12-01T05:43:53.837077Z","iopub.status.idle":"2021-12-01T05:43:57.752551Z","shell.execute_reply.started":"2021-12-01T05:43:53.836986Z","shell.execute_reply":"2021-12-01T05:43:57.751834Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_labels = pd.read_csv(\"/kaggle/input/histopathologic-cancer-detection/train_labels.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-01T05:43:57.753966Z","iopub.execute_input":"2021-12-01T05:43:57.754630Z","iopub.status.idle":"2021-12-01T05:43:58.277673Z","shell.execute_reply.started":"2021-12-01T05:43:57.754599Z","shell.execute_reply":"2021-12-01T05:43:58.276899Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_labels.hist()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T05:43:58.279147Z","iopub.execute_input":"2021-12-01T05:43:58.279409Z","iopub.status.idle":"2021-12-01T05:43:58.546037Z","shell.execute_reply.started":"2021-12-01T05:43:58.279374Z","shell.execute_reply":"2021-12-01T05:43:58.545364Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T05:43:58.548007Z","iopub.execute_input":"2021-12-01T05:43:58.548401Z","iopub.status.idle":"2021-12-01T05:43:59.062508Z","shell.execute_reply.started":"2021-12-01T05:43:58.548364Z","shell.execute_reply":"2021-12-01T05:43:59.061780Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Approximately 60% of the training images are negative and 40% are positive.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"img = plt.imread(\"/kaggle/input/histopathologic-cancer-detection/train/6ab1cdb88dce07be766df5a7b2c7af8edd982ab4.tif\", 3)\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T05:43:59.063857Z","iopub.execute_input":"2021-12-01T05:43:59.064125Z","iopub.status.idle":"2021-12-01T05:43:59.289869Z","shell.execute_reply.started":"2021-12-01T05:43:59.064092Z","shell.execute_reply":"2021-12-01T05:43:59.289231Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Sanity checking an image suggests that the color channels could contain relevant information.","metadata":{}},{"cell_type":"code","source":"# root, dirs, files\ntrain_directory = \"/kaggle/input/histopathologic-cancer-detection/train\"\ntrain_file_list = [files for root, dirs, files in os.walk(train_directory)][0]\ntrain_file_df = pd.DataFrame(train_file_list, columns=['filepath'])\ntrain_file_df['id'] = train_file_df['filepath'].apply(lambda x: x[:-4])\ncombined_df = pd.concat([train_file_df.set_index('id'), train_labels.set_index('id')], axis=1)\ncombined_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T05:43:59.290794Z","iopub.execute_input":"2021-12-01T05:43:59.291044Z","iopub.status.idle":"2021-12-01T05:46:32.630403Z","shell.execute_reply.started":"2021-12-01T05:43:59.291010Z","shell.execute_reply":"2021-12-01T05:46:32.629733Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nif not os.path.exists(\"/kaggle/working/train\"):\n    os.mkdir(\"/kaggle/working/train\")\n    \nif not os.path.exists(\"/kaggle/working/train/0\"):\n    os.mkdir(\"/kaggle/working/train/0\")\n\nif not os.path.exists(\"/kaggle/working/train/1\"):\n    os.mkdir(\"/kaggle/working/train/1\")\n\nworking_train_directory = \"/kaggle/working/train\"\n    \nfor _, row in combined_df.iterrows():\n    shutil.copyfile(os.path.join(train_directory, row['filepath']), os.path.join(working_train_directory, str(row['label']), row['filepath']))","metadata":{"execution":{"iopub.status.busy":"2021-12-01T05:46:32.631596Z","iopub.execute_input":"2021-12-01T05:46:32.631835Z","iopub.status.idle":"2021-12-01T06:06:32.083575Z","shell.execute_reply.started":"2021-12-01T05:46:32.631802Z","shell.execute_reply":"2021-12-01T06:06:32.082794Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"In order to format the training set for the preprocessor, the images are moved into the working directory and separated by their class into two folders \"0\" and \"1\", based on the data extracted from the provided train_labels.csv file. This automates the process of providing labels to the model for fitting.","metadata":{}},{"cell_type":"code","source":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:06:32.084984Z","iopub.execute_input":"2021-12-01T06:06:32.085238Z","iopub.status.idle":"2021-12-01T06:06:33.010727Z","shell.execute_reply.started":"2021-12-01T06:06:32.085206Z","shell.execute_reply":"2021-12-01T06:06:33.009986Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"The preprocessor shears and zooms the images, as well as flips them horizontally at random. This allows the model to generalize better. The process of randomly adjusting images to increase a model's generalization is called augmentation.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    working_train_directory,\n    target_size=(96, 96),\n    batch_size = 128,\n    class_mode = 'binary'\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:25:30.280878Z","iopub.execute_input":"2021-12-01T06:25:30.281551Z","iopub.status.idle":"2021-12-01T06:25:35.573540Z","shell.execute_reply.started":"2021-12-01T06:25:30.281511Z","shell.execute_reply":"2021-12-01T06:25:35.572800Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_generator.class_indices","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:25:35.575281Z","iopub.execute_input":"2021-12-01T06:25:35.575552Z","iopub.status.idle":"2021-12-01T06:25:35.581189Z","shell.execute_reply.started":"2021-12-01T06:25:35.575504Z","shell.execute_reply":"2021-12-01T06:25:35.580490Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# get dimensions of image\nimg_dim = (img.size / 3) ** 0.5\nprint(img_dim)\ninput_layer_size = img.size\nprint(input_layer_size)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:25:35.582542Z","iopub.execute_input":"2021-12-01T06:25:35.583009Z","iopub.status.idle":"2021-12-01T06:25:35.595862Z","shell.execute_reply.started":"2021-12-01T06:25:35.582971Z","shell.execute_reply":"2021-12-01T06:25:35.595115Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Model Architecture","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential()\n\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation=\"relu\",input_shape=(96,96,3)))\nmodel.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\nmodel.add(tf.keras.layers.MaxPooling2D(2, 2))\nmodel.add(tf.keras.layers.Dropout(0.25))\n\nmodel.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\nmodel.add(tf.keras.layers.MaxPooling2D(2, 2))\nmodel.add(tf.keras.layers.Dropout(0.25))\n\nmodel.add(tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"))\nmodel.add(tf.keras.layers.MaxPooling2D(2, 2))\nmodel.add(tf.keras.layers.Dropout(0.4))\n\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.3))\n\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=0.0003,\n    decay_steps=10000,\n    decay_rate=0.9)\n\nopt = tf.keras.optimizers.Adam(lr_schedule)\n\nmodel.compile(optimizer=opt,loss='binary_crossentropy',metrics=[tf.keras.metrics.BinaryAccuracy(),\n                       tf.keras.metrics.FalseNegatives()])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:25:35.597811Z","iopub.execute_input":"2021-12-01T06:25:35.598238Z","iopub.status.idle":"2021-12-01T06:25:35.701707Z","shell.execute_reply.started":"2021-12-01T06:25:35.598204Z","shell.execute_reply":"2021-12-01T06:25:35.700982Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"The CNN is configured with a repeating pattern of Conv2D with ReLu activation, MaxPooling, and Dropout layers. At the end there is a fully connected Linear layer before the final output layer. The output layer contains a single dimension because the classification problem has 2 classes (0 and 1). I studied multiple examples of CNNs for binary classification and this approach seemed to be well supported by those examples successfully performing binary classification on a set of images. Generally speaking, the rule of thumb for successive layers is to reduce the number of dimensions by 0.5 as stepping through the network. The dropout layers help to isolate important features. Also worth noting is the use of a decaying learning rate on the Adam optimizer. The learning rate will decay exponentially over a set number of steps. The purpose of decaying the learning rate is to accelerate learning at the outset of training but reduce it over time to allow for exploring fine details at the end of the training period.","metadata":{}},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:25:35.703057Z","iopub.execute_input":"2021-12-01T06:25:35.703299Z","iopub.status.idle":"2021-12-01T06:25:35.711383Z","shell.execute_reply.started":"2021-12-01T06:25:35.703266Z","shell.execute_reply":"2021-12-01T06:25:35.710698Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator, steps_per_epoch=100, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:25:35.712520Z","iopub.execute_input":"2021-12-01T06:25:35.712770Z","iopub.status.idle":"2021-12-01T06:32:16.756459Z","shell.execute_reply.started":"2021-12-01T06:25:35.712734Z","shell.execute_reply":"2021-12-01T06:32:16.755633Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"The main consideration for the hyperparameters of steps_per_epoch and epochs is RAM. If these values are too high, the amount of RAM needed exceeds the available memory on the GPU. Another consideration is that too low a value would mean the model is training on a limited portion of the dataset, as well as the stepwise decay rate for the learning_rate parameter.\n\nLearning rate is another hugely important hyperparameter that I tuned mostly through trial and error. Too high a learning rate and the model seems to converge on a roughly 60% accuracy rate but not exceeding it. Since roughly 60% of the training data is 0, one can imagine a scenario where the classifier just classifies all the samples are negative and achieves a 60% accuracy rate. Too low a learning rate and the model struggles to fit the data. I experienced this with a large batch size, as false negative rate just spiralled out of control with too high a value.","metadata":{}},{"cell_type":"code","source":"# model.save(\"/kaggle/working/113021.hd5\")","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:07:22.498291Z","iopub.status.idle":"2021-12-01T06:07:22.498622Z","shell.execute_reply.started":"2021-12-01T06:07:22.498435Z","shell.execute_reply":"2021-12-01T06:07:22.498455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Results","metadata":{}},{"cell_type":"code","source":"# root, dirs, files\ntest_directory = \"/kaggle/input/histopathologic-cancer-detection/test\"","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:32:27.002911Z","iopub.execute_input":"2021-12-01T06:32:27.003521Z","iopub.status.idle":"2021-12-01T06:32:27.007635Z","shell.execute_reply.started":"2021-12-01T06:32:27.003481Z","shell.execute_reply":"2021-12-01T06:32:27.006650Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nif not os.path.exists(\"/kaggle/working/test\"):\n    os.mkdir(\"/kaggle/working/test\")\n    \nif not os.path.exists(\"/kaggle/working/test/predict\"):\n    os.mkdir(\"/kaggle/working/test/predict\")\n\nworking_test_directory = \"/kaggle/working/test\"\n    \nfor root, dirs, filenames in os.walk(test_directory):\n    for filename in filenames:\n            shutil.copyfile(os.path.join(test_directory, filename), os.path.join(working_test_directory, 'predict', filename))\n        ","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:32:27.880740Z","iopub.execute_input":"2021-12-01T06:32:27.881498Z","iopub.status.idle":"2021-12-01T06:37:20.997272Z","shell.execute_reply.started":"2021-12-01T06:32:27.881452Z","shell.execute_reply":"2021-12-01T06:37:20.996438Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"A similar process as the training set formatting is conducted for moving test files into the working directory, with the exception being that the preprocessor expects a single directory containing the test images inside the root test directory.","metadata":{}},{"cell_type":"code","source":"test_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n\ntest_generator = test_datagen.flow_from_directory(\n    directory=working_test_directory,\n    target_size=(96, 96),\n    color_mode=\"rgb\",\n    batch_size=1,\n    class_mode=None,\n    shuffle=False\n)\n\npredict =model.predict(test_generator)\n# predict the class label","metadata":{"execution":{"iopub.status.busy":"2021-12-01T07:23:24.986717Z","iopub.execute_input":"2021-12-01T07:23:24.987008Z","iopub.status.idle":"2021-12-01T07:25:13.577490Z","shell.execute_reply.started":"2021-12-01T07:23:24.986965Z","shell.execute_reply":"2021-12-01T07:25:13.576714Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"predict[:10]","metadata":{"execution":{"iopub.status.busy":"2021-12-01T07:25:13.579473Z","iopub.execute_input":"2021-12-01T07:25:13.579732Z","iopub.status.idle":"2021-12-01T07:25:13.587628Z","shell.execute_reply.started":"2021-12-01T07:25:13.579697Z","shell.execute_reply":"2021-12-01T07:25:13.586712Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"y_classes = predict","metadata":{"execution":{"iopub.status.busy":"2021-12-01T07:18:13.048607Z","iopub.execute_input":"2021-12-01T07:18:13.049843Z","iopub.status.idle":"2021-12-01T07:18:13.055857Z","shell.execute_reply.started":"2021-12-01T07:18:13.049798Z","shell.execute_reply":"2021-12-01T07:18:13.055067Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"markdown","source":"Limiting the batch size to 1 and setting shuffle to False retains the ordering of the labels for constructing the submission.csv file.","metadata":{}},{"cell_type":"code","source":"y_ids = test_generator.filenames\ny_ids[10:]","metadata":{"execution":{"iopub.status.busy":"2021-12-01T07:22:34.607228Z","iopub.execute_input":"2021-12-01T07:22:34.608003Z","iopub.status.idle":"2021-12-01T07:22:34.614951Z","shell.execute_reply.started":"2021-12-01T07:22:34.607963Z","shell.execute_reply":"2021-12-01T07:22:34.614078Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"formatted_y_ids = [fid[8:-4] for fid in y_ids]","metadata":{"execution":{"iopub.status.busy":"2021-12-01T07:25:58.009626Z","iopub.execute_input":"2021-12-01T07:25:58.010298Z","iopub.status.idle":"2021-12-01T07:25:58.028459Z","shell.execute_reply.started":"2021-12-01T07:25:58.010257Z","shell.execute_reply":"2021-12-01T07:25:58.027728Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"formatted_y_ids[:10]","metadata":{"execution":{"iopub.status.busy":"2021-12-01T07:25:58.751607Z","iopub.execute_input":"2021-12-01T07:25:58.752210Z","iopub.status.idle":"2021-12-01T07:25:58.759774Z","shell.execute_reply.started":"2021-12-01T07:25:58.752168Z","shell.execute_reply":"2021-12-01T07:25:58.758929Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"len(y_classes)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T07:11:45.868853Z","iopub.execute_input":"2021-12-01T07:11:45.869557Z","iopub.status.idle":"2021-12-01T07:11:45.875799Z","shell.execute_reply.started":"2021-12-01T07:11:45.869516Z","shell.execute_reply":"2021-12-01T07:11:45.875041Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"len(y_ids)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T07:11:46.358378Z","iopub.execute_input":"2021-12-01T07:11:46.361115Z","iopub.status.idle":"2021-12-01T07:11:46.368529Z","shell.execute_reply.started":"2021-12-01T07:11:46.361068Z","shell.execute_reply":"2021-12-01T07:11:46.367670Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"history.history.keys()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T07:11:47.013699Z","iopub.execute_input":"2021-12-01T07:11:47.013975Z","iopub.status.idle":"2021-12-01T07:11:47.019552Z","shell.execute_reply.started":"2021-12-01T07:11:47.013942Z","shell.execute_reply":"2021-12-01T07:11:47.018889Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='Binary Classification Loss')\nplt.plot(history.history['binary_accuracy'], label='Binary Accuracy')\nplt.title('Training History')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(loc=\"upper left\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T07:11:47.566151Z","iopub.execute_input":"2021-12-01T07:11:47.566962Z","iopub.status.idle":"2021-12-01T07:11:47.771341Z","shell.execute_reply.started":"2021-12-01T07:11:47.566895Z","shell.execute_reply":"2021-12-01T07:11:47.770606Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['false_negatives_4'], label='False Negatives')\nplt.title('Training History (False Negatives)')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(loc=\"upper left\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T07:11:48.429714Z","iopub.execute_input":"2021-12-01T07:11:48.430267Z","iopub.status.idle":"2021-12-01T07:11:48.623045Z","shell.execute_reply.started":"2021-12-01T07:11:48.430227Z","shell.execute_reply":"2021-12-01T07:11:48.622371Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"predict_df = pd.DataFrame({'id':formatted_y_ids, 'label': y_classes.flatten()})","metadata":{"execution":{"iopub.status.busy":"2021-12-01T07:30:27.073008Z","iopub.execute_input":"2021-12-01T07:30:27.073745Z","iopub.status.idle":"2021-12-01T07:30:27.087125Z","shell.execute_reply.started":"2021-12-01T07:30:27.073705Z","shell.execute_reply":"2021-12-01T07:30:27.086269Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"# sanity check the prediction dataframe before export\npredict_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T07:30:28.591435Z","iopub.execute_input":"2021-12-01T07:30:28.591711Z","iopub.status.idle":"2021-12-01T07:30:28.601064Z","shell.execute_reply.started":"2021-12-01T07:30:28.591683Z","shell.execute_reply":"2021-12-01T07:30:28.600315Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"predict_df.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T07:30:48.909304Z","iopub.execute_input":"2021-12-01T07:30:48.909593Z","iopub.status.idle":"2021-12-01T07:30:49.135706Z","shell.execute_reply.started":"2021-12-01T07:30:48.909562Z","shell.execute_reply":"2021-12-01T07:30:49.134842Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":"The final accuracy of the model on the training set was approximately 80%.","metadata":{}}]}